{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2617b571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 54.59884830498453\n",
      "Mean Absolute Error: 5.418032735899173\n",
      "R-squared: 0.6745414195692574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(\"RealEstate.xlsx\")\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=[\"Y house price of unit area\"])\n",
    "y = df[\"Y house price of unit area\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c725d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics using PCA:\n",
      "Mean Squared Error: 58.77464185501734\n",
      "Mean Absolute Error: 5.82883266736957\n",
      "R-squared: 0.6496499084264946\n",
      "Performance Metrics without PCA:\n",
      "Mean Squared Error: 54.59884830498453\n",
      "Mean Absolute Error: 5.418032735899173\n",
      "R-squared: 0.6745414195692574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Comparing the performance of the model using PCA with the performance obtained in Q1, we can observe the following:\\n\\n1. Mean Squared Error (MSE):\\n   - Without PCA: 54.5988\\n   - With PCA: 58.7746\\n   The MSE is slightly higher when using PCA, indicating that the model's predictions have higher errors on average compared to the model trained on the original dataset.\\n\\n2. Mean Absolute Error (MAE):\\n   - Without PCA: 5.4180\\n   - With PCA: 5.8288\\n   Similarly, the MAE is slightly higher when using PCA, indicating that the absolute errors of the model's predictions are slightly larger with the reduced-dimensional representation.\\n\\n3. R-squared (R2):\\n   - Without PCA: 0.6745\\n   - With PCA: 0.6496\\n   The R-squared value is lower when using PCA, indicating that the model explains less of the variance in the target variable compared to the model trained on the original dataset.\\n\\nThese results suggest that while PCA helps in reducing the dimensionality of the dataset, it also results in a slight decrease in predictive performance. The reduction in performance is relatively small, which indicates that the first three principal components capture a substantial portion of the variance in the original dataset. However, there is still some loss of information during the dimensionality reduction process, leading to slightly inferior performance compared to the model trained on the full set of features.\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(\"RealEstate.xlsx\")\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=[\"Y house price of unit area\"])\n",
    "y = df[\"Y house price of unit area\"]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_pca = mean_squared_error(y_test, y_pred)\n",
    "mae_pca = mean_absolute_error(y_test, y_pred)\n",
    "r2_pca = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Performance Metrics using PCA:\")\n",
    "print(\"Mean Squared Error:\", mse_pca)\n",
    "print(\"Mean Absolute Error:\", mae_pca)\n",
    "print(\"R-squared:\", r2_pca)\n",
    "\n",
    "print(\"Performance Metrics without PCA:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "\"\"\"Comparing the performance of the model using PCA with the performance obtained in Q1, we can observe the following:\n",
    "\n",
    "1. Mean Squared Error (MSE):\n",
    "   - Without PCA: 54.5988\n",
    "   - With PCA: 58.7746\n",
    "   The MSE is slightly higher when using PCA, indicating that the model's predictions have higher errors on average compared to the model trained on the original dataset.\n",
    "\n",
    "2. Mean Absolute Error (MAE):\n",
    "   - Without PCA: 5.4180\n",
    "   - With PCA: 5.8288\n",
    "   Similarly, the MAE is slightly higher when using PCA, indicating that the absolute errors of the model's predictions are slightly larger with the reduced-dimensional representation.\n",
    "\n",
    "3. R-squared (R2):\n",
    "   - Without PCA: 0.6745\n",
    "   - With PCA: 0.6496\n",
    "   The R-squared value is lower when using PCA, indicating that the model explains less of the variance in the target variable compared to the model trained on the original dataset.\n",
    "\n",
    "These results suggest that while PCA helps in reducing the dimensionality of the dataset, it also results in a slight decrease in predictive performance. The reduction in performance is relatively small, which indicates that the first three principal components capture a substantial portion of the variance in the original dataset. However, there is still some loss of information during the dimensionality reduction process, leading to slightly inferior performance compared to the model trained on the full set of features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013bfe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Performance Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc66255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics with L1 Regularization:\n",
      "Accuracy: 0.9666666666666667\n",
      "Precision: 0.9694444444444444\n",
      "Recall: 0.9666666666666667\n",
      "F1 Score: 0.9664109121909632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"  Let's compare the performance metrics of the logistic regression model with L1 regularization to the performance reported in Q3:\\n\\nPerformance Metrics with L1 Regularization:\\n- Accuracy: 0.9667\\n- Precision: 0.9694\\n- Recall: 0.9667\\n- F1 Score: 0.9664\\n\\nPerformance Metrics from Q3:\\n- Accuracy: 0.9667\\n- Precision: 0.9694\\n- Recall: 0.9667\\n- F1 Score: 0.9664\\n\\nThe performance metrics with L1 regularization are almost identical to the performance reported in Q3 without regularization. This outcome suggests that the addition of L1 regularization did not significantly impact the model's performance on this dataset.\\n\\nExplanation:\\n- Accuracy, Precision, Recall, and F1 Score: The similarity in performance metrics indicates that the logistic regression model with L1 regularization achieved comparable results to the model without regularization. In this case, the dataset may not have required regularization to prevent overfitting, or the amount of regularization applied with L1 regularization was not sufficient to affect the model's performance noticeably.\\n\\nOverall, the outcome suggests that the logistic regression model was well-suited for the Iris dataset, and the addition of L1 regularization did not lead to significant improvements or changes in performance. Regularization techniques like L1 can be particularly useful when dealing with high-dimensional datasets or when there's a risk of overfitting, but in this case, the dataset and model were already well-balanced.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model with L1 regularization\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear')  # L1 regularization with solver set to 'liblinear'\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Performance Metrics with L1 Regularization:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\"\"\"  Let's compare the performance metrics of the logistic regression model with L1 regularization to the performance reported in Q3:\n",
    "\n",
    "Performance Metrics with L1 Regularization:\n",
    "- Accuracy: 0.9667\n",
    "- Precision: 0.9694\n",
    "- Recall: 0.9667\n",
    "- F1 Score: 0.9664\n",
    "\n",
    "Performance Metrics from Q3:\n",
    "- Accuracy: 0.9667\n",
    "- Precision: 0.9694\n",
    "- Recall: 0.9667\n",
    "- F1 Score: 0.9664\n",
    "\n",
    "The performance metrics with L1 regularization are almost identical to the performance reported in Q3 without regularization. This outcome suggests that the addition of L1 regularization did not significantly impact the model's performance on this dataset.\n",
    "\n",
    "Explanation:\n",
    "- Accuracy, Precision, Recall, and F1 Score: The similarity in performance metrics indicates that the logistic regression model with L1 regularization achieved comparable results to the model without regularization. In this case, the dataset may not have required regularization to prevent overfitting, or the amount of regularization applied with L1 regularization was not sufficient to affect the model's performance noticeably.\n",
    "\n",
    "Overall, the outcome suggests that the logistic regression model was well-suited for the Iris dataset, and the addition of L1 regularization did not lead to significant improvements or changes in performance. Regularization techniques like L1 can be particularly useful when dealing with high-dimensional datasets or when there's a risk of overfitting, but in this case, the dataset and model were already well-balanced.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1089fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
