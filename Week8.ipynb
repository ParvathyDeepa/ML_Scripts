{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f0cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Accuracy: 0.7895\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.70      0.68      0.69       693\n",
      "    unstable       0.83      0.85      0.84      1307\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.77      0.76      0.77      2000\n",
      "weighted avg       0.79      0.79      0.79      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Comparing the two models (this week and week 7 qn 2), we observe that the SVM model outperforms the KNN model in terms of accuracy and F1-scores for both classes (stable and unstable). The SVM model achieves higher accuracy and better precision-recall balance for both classes compared to the KNN model. This suggests that the SVM model with a linear kernel is more suitable for this classification task compared to the KNN model.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Task7.1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['stabf'])\n",
    "y = data['stabf']\n",
    "\n",
    "# Splitting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Report Performance and Hyperparameters\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "\"\"\"Comparing the two models (this week and week 7 qn 2), we observe that the SVM model outperforms the KNN model in terms of accuracy and F1-scores for both classes (stable and unstable). The SVM model achieves higher accuracy and better precision-recall balance for both classes compared to the KNN model. This suggests that the SVM model with a linear kernel is more suitable for this classification task compared to the KNN model.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b878929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance with 50-50% Split:\n",
      "Accuracy: 0.9998\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       1.00      1.00      1.00      1795\n",
      "    unstable       1.00      1.00      1.00      3205\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n",
      "\n",
      "Model Performance with 80-20% Split:\n",
      "Accuracy: 0.9995\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       1.00      1.00      1.00       693\n",
      "    unstable       1.00      1.00      1.00      1307\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Task7.1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['stabf'])\n",
    "y = data['stabf']\n",
    "\n",
    "# Model Training and Evaluation with 50-50% data splitting\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "dt_model_50 = DecisionTreeClassifier(random_state=42)\n",
    "dt_model_50.fit(X_train_50, y_train_50)\n",
    "y_pred_50 = dt_model_50.predict(X_test_50)\n",
    "accuracy_50 = accuracy_score(y_test_50, y_pred_50)\n",
    "report_50 = classification_report(y_test_50, y_pred_50)\n",
    "\n",
    "# Model Training and Evaluation with 80-20% data splitting\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt_model_80 = DecisionTreeClassifier(random_state=42)\n",
    "dt_model_80.fit(X_train_80, y_train_80)\n",
    "y_pred_80 = dt_model_80.predict(X_test_80)\n",
    "accuracy_80 = accuracy_score(y_test_80, y_pred_80)\n",
    "report_80 = classification_report(y_test_80, y_pred_80)\n",
    "\n",
    "# Print the performances and comparison\n",
    "print(\"Model Performance with 50-50% Split:\")\n",
    "print(\"Accuracy:\", accuracy_50)\n",
    "print(\"Classification Report:\")\n",
    "print(report_50)\n",
    "print(\"\\nModel Performance with 80-20% Split:\")\n",
    "print(\"Accuracy:\", accuracy_80)\n",
    "print(\"Classification Report:\")\n",
    "print(report_80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2b9dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Both models achieve very high accuracy, precision, recall, and F1-score values, indicating excellent performance in classifying the electrical grid stability data.\\n\\nThe main difference between the two models lies in the size of the training and testing sets due to the different data splitting methods:\\n\\n1. **50-50% Split Model:**\\n   - **Accuracy:** 99.98%\\n   - **Training Set Size:** 5000 samples\\n   - **Testing Set Size:** 5000 samples\\n   - The model trained on a larger dataset (5000 samples) has slightly higher accuracy compared to the 80-20% split model. This larger dataset provides more information for the model to learn from, leading to better performance.\\n   - The classification report shows perfect precision, recall, and F1-score values for both stable and unstable classes, indicating no misclassifications in the testing set.\\n\\n2. **80-20% Split Model:**\\n   - **Accuracy:** 99.95%\\n   - **Training Set Size:** 4000 samples\\n   - **Testing Set Size:** 2000 samples\\n   - The model trained on a smaller dataset (4000 samples) with a smaller training set proportion achieves slightly lower accuracy compared to the 50-50% split model.\\n   - Despite the smaller training set, the model still performs exceptionally well with perfect precision, recall, and F1-score values for both classes in the testing set.\\n\\nOverall, both models demonstrate high performance, but the 50-50% split model benefits from a larger training dataset, resulting in slightly higher accuracy. The impact of the difference in data splitting on the performances of the models showcases the importance of having sufficient data for training to achieve optimal model performance. However, even with a smaller training set in the 80-20% split model, the decision tree algorithm proves to be robust and highly effective in classifying the electrical grid stability data.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Both models achieve very high accuracy, precision, recall, and F1-score values, indicating excellent performance in classifying the electrical grid stability data.\n",
    "\n",
    "The main difference between the two models lies in the size of the training and testing sets due to the different data splitting methods:\n",
    "\n",
    "1. 50-50% Split Model:\n",
    "   - Accuracy:99.98%\n",
    "   - Training Set Size: 5000 samples\n",
    "   - Testing Set Size: 5000 samples\n",
    "   - The model trained on a larger dataset (5000 samples) has slightly higher accuracy compared to the 80-20% split model. This larger dataset provides more information for the model to learn from, leading to better performance.\n",
    "   - The classification report shows perfect precision, recall, and F1-score values for both stable and unstable classes, indicating no misclassifications in the testing set.\n",
    "\n",
    "2. 80-20% Split Model:\n",
    "   - Accuracy: 99.95%\n",
    "   - Training Set Size: 4000 samples\n",
    "   - Testing Set Size: 2000 samples\n",
    "   - The model trained on a smaller dataset (4000 samples) with a smaller training set proportion achieves slightly lower accuracy compared to the 50-50% split model.\n",
    "   - Despite the smaller training set, the model still performs exceptionally well with perfect precision, recall, and F1-score values for both classes in the testing set.\n",
    "\n",
    "Overall, both models demonstrate high performance, but the 50-50% split model benefits from a larger training dataset, resulting in slightly higher accuracy. The impact of the difference in data splitting on the performances of the models showcases the importance of having sufficient data for training to achieve optimal model performance. However, even with a smaller training set in the 80-20% split model, the decision tree algorithm proves to be robust and highly effective in classifying the electrical grid stability data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f9cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with Euclidean Distance Metric:\n",
      "Accuracy: 0.7895\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.70      0.68      0.69       693\n",
      "    unstable       0.83      0.85      0.84      1307\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.77      0.76      0.77      2000\n",
      "weighted avg       0.79      0.79      0.79      2000\n",
      "\n",
      "\n",
      "Performance with Cityblock Distance Metric:\n",
      "Accuracy: 0.819\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.74      0.73      0.74       693\n",
      "    unstable       0.86      0.87      0.86      1307\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.80      0.80      0.80      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n",
      "\n",
      "Performance with Manhattan Distance Metric:\n",
      "Accuracy: 0.819\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.74      0.73      0.74       693\n",
      "    unstable       0.86      0.87      0.86      1307\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.80      0.80      0.80      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Task7.1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['stabf'])\n",
    "y = data['stabf']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train KNN classifiers with different distance metrics\n",
    "knn_euclidean = KNeighborsClassifier()\n",
    "knn_euclidean.fit(X_train, y_train)\n",
    "\n",
    "knn_cityblock = KNeighborsClassifier(metric='cityblock')\n",
    "knn_cityblock.fit(X_train, y_train)\n",
    "\n",
    "knn_manhattan = KNeighborsClassifier(metric='manhattan')\n",
    "knn_manhattan.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report\n",
    "\n",
    "accuracy_euclidean, report_euclidean = evaluate_model(knn_euclidean, X_test, y_test)\n",
    "accuracy_cityblock, report_cityblock = evaluate_model(knn_cityblock, X_test, y_test)\n",
    "accuracy_manhattan, report_manhattan = evaluate_model(knn_manhattan, X_test, y_test)\n",
    "\n",
    "# Report the performances\n",
    "print(\"Performance with Euclidean Distance Metric:\")\n",
    "print(\"Accuracy:\", accuracy_euclidean)\n",
    "print(\"Classification Report:\")\n",
    "print(report_euclidean)\n",
    "\n",
    "print(\"\\nPerformance with Cityblock Distance Metric:\")\n",
    "print(\"Accuracy:\", accuracy_cityblock)\n",
    "print(\"Classification Report:\")\n",
    "print(report_cityblock)\n",
    "\n",
    "print(\"\\nPerformance with Manhattan Distance Metric:\")\n",
    "print(\"Accuracy:\", accuracy_manhattan)\n",
    "print(\"Classification Report:\")\n",
    "print(report_manhattan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84695285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\nThe above results indicate that both the models using cityblock and Manhattan distance metrics have slightly higher accuracy compared to the model using the Euclidean distance metric. However, the differences in accuracy are marginal.\\n\\nLooking at the classification reports, we can see that the precision, recall, and F1-score values for both stable and unstable classes are quite similar between the models using cityblock and Manhattan distance metrics. This similarity suggests that these two distance metrics might be capturing similar underlying structures in the data, leading to comparable classification performance.\\n\\nOverall, all three models demonstrate good performance, but the models using cityblock and Manhattan distance metrics show a slight improvement in accuracy compared to the model using the Euclidean distance metric. However, the differences in performance are relatively small, indicating that the choice of distance metric may not have a significant impact on the classification performance in this particular dataset.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "The above results indicate that both the models using cityblock and Manhattan distance metrics have slightly higher accuracy compared to the model using the Euclidean distance metric. However, the differences in accuracy are marginal.\n",
    "\n",
    "Looking at the classification reports, we can see that the precision, recall, and F1-score values for both stable and unstable classes are quite similar between the models using cityblock and Manhattan distance metrics. This similarity suggests that these two distance metrics might be capturing similar underlying structures in the data, leading to comparable classification performance.\n",
    "\n",
    "Overall, all three models demonstrate good performance, but the models using cityblock and Manhattan distance metrics show a slight improvement in accuracy compared to the model using the Euclidean distance metric. However, the differences in performance are relatively small, indicating that the choice of distance metric may not have a significant impact on the classification performance in this particular dataset.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3e807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
